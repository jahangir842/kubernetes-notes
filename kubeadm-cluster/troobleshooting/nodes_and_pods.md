Your output shows a healthy cluster on `k8s-master` with all pods in the `kube-system` namespace running successfullyâ€”great work! Youâ€™ve noticed that the IP addresses assigned to the pods fall into two different ranges: `192.168.1.190` and `172.17.235.193-196`. This is expected behavior in a Kubernetes cluster and reflects the distinction between *node IPs* and *pod IPs*. Let me explain why this happens and how it ties into your setup with kubeadm, Calico, and containerd.

---

### Why Different IP Ranges?
In Kubernetes, IP addresses are assigned based on the type of component and the networking configuration:

1. **Node IPs (`192.168.1.190`)**:
   - Pods like `etcd-k8s-master`, `kube-apiserver-k8s-master`, `kube-controller-manager-k8s-master`, `kube-scheduler-k8s-master`, and `calico-node-dtbnz` have the IP `192.168.1.190`.
   - **Reason**: These are *host-networked pods*, meaning they run directly on the nodeâ€™s network stack and use the nodeâ€™s IP address (`192.168.1.190`, your `k8s-master` static IP).
   - **Details**:
     - Control plane components (`etcd`, `kube-apiserver`, etc.) are static pods managed by the kubelet and configured to use `hostNetwork: true` in their manifests (located in `/etc/kubernetes/manifests/`).
     - `calico-node` also uses `hostNetwork: true` because it needs direct access to the nodeâ€™s network interfaces to manage Calicoâ€™s networking (e.g., BGP, IP routing).

2. **Pod IPs (`172.17.235.193-196`)**:
   - Pods like `calico-kube-controllers-7ddc4f45bc-d2kgh`, `coredns-64ff69f7fc-kp4gm`, and `coredns-64ff69f7fc-z555c` have IPs in the `172.17.235.0/24` range.
   - **Reason**: These are *regular pods* that run in the Kubernetes pod network, which is managed by the Container Network Interface (CNI) pluginâ€”Calico in your case.
   - **Details**:
     - When you initialized the cluster with `kubeadm init --pod-network-cidr=192.168.0.0/16`, you specified the pod network CIDR, which defines the range of IPs available for pods.
     - Calico allocates pod IPs from this range (or a subset of it), but in your output, itâ€™s using `172.17.235.0/24`. This mismatch suggests Calico might be overriding the default CIDR or using an unexpected range.

---

### Understanding the IP Ranges
- **`192.168.1.190`**:
  - This is your nodeâ€™s physical (or virtual) network IP, set via `nmcli` earlier (`192.168.1.190/24`).
  - Pods using `hostNetwork: true` inherit this IP because they donâ€™t get a separate network namespaceâ€”they share the nodeâ€™s.

- **`172.17.235.193-196`**:
  - These are pod IPs assigned by Calico from its configured IP pool.
  - **Unexpected Range**: You specified `--pod-network-cidr=192.168.0.0/16` during `kubeadm init`, so youâ€™d expect pod IPs in that range (e.g., `192.168.x.y`). The appearance of `172.17.235.0/24` suggests:
    1. Calicoâ€™s default IP pool might not have been updated to match your specified CIDR.
    2. A misconfiguration or fallback to a default range (possibly from an earlier setup or Calicoâ€™s defaults).

---

### Why This Matters
- **Functionality**: The cluster works fine with these IPs because:
  - `hostNetwork` pods need the node IP to operate correctly (e.g., API server on `192.168.1.190:6443`).
  - Pod IPs (e.g., `172.17.235.x`) are routable within the cluster via Calico, allowing communication between pods.
- **Potential Issue**: The mismatch between your `--pod-network-cidr=192.168.0.0/16` and the actual pod IPs (`172.17.235.x`) could cause confusion or conflicts later, especially when joining worker nodes or scaling the cluster.

---

### Steps to Investigate and Fix

#### 1. Verify Pod Network CIDR
Check the clusterâ€™s configuration:
```bash
kubectl describe cm kubeadm-config -n kube-system
```
- Look for `podSubnet` under `ClusterConfiguration`. It should say `192.168.0.0/16`.

#### 2. Check Calico IP Pool
Calico manages pod IPs via its `IPPool` resource:
```bash
kubectl get ippool -n kube-system
```
- If no output, Calico is using a default pool. Fetch the default:
  ```bash
  kubectl get ippool default-ipv4-ippool -n kube-system -o yaml
  ```
- Expected `spec.cidr` should be `192.168.0.0/16`. If itâ€™s `172.17.235.0/24` or similar, itâ€™s misconfigured.

Fix the IP pool (if needed):
- Edit the pool:
  ```bash
  kubectl edit ippool default-ipv4-ippool -n kube-system
  ```
- Set `spec.cidr` to `192.168.0.0/16`:
  ```yaml
  spec:
    cidr: 192.168.0.0/16
  ```
- Restart Calico pods:
  ```bash
  kubectl delete pod -l k8s-app=calico-node -n kube-system
  kubectl delete pod -l k8s-app=calico-kube-controllers -n kube-system
  ```
- New pods should use `192.168.x.y` IPs.

#### 3. Verify Node Status
Since `kube-proxy` is still missing, the node might be `NotReady`:
```bash
kubectl get nodes -o wide
```

#### 4. Deploy Kube-Proxy
Add `kube-proxy` to complete the setup:
```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/kubeadm/master/hack/static-yaml/kube-proxy.yaml
```
Check:
```bash
kubectl get pods -n kube-system -o wide | grep kube-proxy
```

#### 5. Re-Verify IPs
After fixing the IP pool and adding `kube-proxy`:
```bash
kubectl get pods -n kube-system -o wide
```
- Pod IPs should align with `192.168.0.0/16` if you updated the IP pool.

---

### Should You Fix the IP Mismatch?
- **If Itâ€™s Working**: The `172.17.235.x` range isnâ€™t inherently wrong if itâ€™s routable and doesnâ€™t conflict with your physical network (`192.168.1.0/24`). You can leave it as-is for now and proceed with joining workers.
- **For Consistency**: Update the Calico IP pool to match `192.168.0.0/16` to align with your `kubeadm init` configuration.

---

### Next Steps
1. Deploy `kube-proxy` (Step 4).
2. Check the IP pool (Step 2) and decide if you want to fix it.
3. Join the worker nodes:
   ```bash
   kubeadm token create --print-join-command
   ```
   On `k8s-worker1` and `k8s-worker2`:
   ```bash
   sudo kubeadm join 192.168.1.190:6443 \
     --token <token> \
     --discovery-token-ca-cert-hash sha256:<hash> \
     --cri-socket=unix:///run/containerd/containerd.sock
   ```

Share the output of `kubectl get nodes -o wide` and `kubectl get pods -n kube-system -o wide` after adding `kube-proxy`â€”Iâ€™ll confirm everythingâ€™s set! ðŸš€ The IP difference is normal due to `hostNetwork` vs. pod network; we just need to ensure consistency if desired.
